{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "FzH4xpRAOnOQ",
        "duz7cGimZzoU",
        "xJ5WbmvIu8nS",
        "_V6EqaaHZ-Hk",
        "AMnNtf5Tdncp",
        "eiL1e6VXsOJi",
        "1ar0acg1sVWS",
        "9pAI_3PZtohf",
        "MKjqQX3kokv8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keeron1/com.mcast.research_design_I_2025.spiteri_keeron/blob/main/src/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Packages"
      ],
      "metadata": {
        "id": "FzH4xpRAOnOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO\n",
        "!pip install torch torchvision opencv-python ultralytics\n",
        "!rm -rf /content/com.mcast.research_design_I_2025.spiteri_keeron\n",
        "\n",
        "# Clone DeepSORT and YOLO model\n",
        "!git clone -n --depth=1 --filter=tree:0 \\\n",
        "  https://github.com/Keeron1/com.mcast.research_design_I_2025.spiteri_keeron.git\n",
        "%cd /content/com.mcast.research_design_I_2025.spiteri_keeron\n",
        "!git sparse-checkout set --no-cone src/deep_sort_pytorch src/yolo\n",
        "!git checkout\n",
        "# Copy folders\n",
        "!rsync -av --remove-source-files src/deep_sort_pytorch/ ../deep_sort_pytorch/\n",
        "!rsync -av --remove-source-files src/yolo/ ../yolo/\n",
        "%cd ..\n",
        "!rm -rf com.mcast.research_design_I_2025.spiteri_keeron # Delete repo directory\n",
        "\n",
        "!pip install -r deep_sort_pytorch/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mIB0om51O7Ky",
        "outputId": "768f6a74-55b4-4441-93bb-1b412800da53"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.116)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Cloning into 'com.mcast.research_design_I_2025.spiteri_keeron'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "Receiving objects: 100% (1/1), done.\n",
            "remote: Total 1 (delta 0), reused 1 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "/content/com.mcast.research_design_I_2025.spiteri_keeron\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 11 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (12/12), 2.09 KiB | 2.09 MiB/s, done.\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 41 (delta 0), reused 40 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (41/41), 86.80 MiB | 34.36 MiB/s, done.\n",
            "Updating files: 100% (44/44), done.\n",
            "Your branch is up to date with 'origin/main'.\n",
            "sending incremental file list\n",
            "./\n",
            ".gitignore\n",
            "LICENSE\n",
            "README.md\n",
            "__init__.py\n",
            "deepsort.py\n",
            "requirements.txt\n",
            "configs/\n",
            "configs/deep_sort.yaml\n",
            "deep_sort/\n",
            "deep_sort/README.md\n",
            "deep_sort/__init__.py\n",
            "deep_sort/deep_sort.py\n",
            "deep_sort/deep/\n",
            "deep_sort/deep/GETTING_STARTED.md\n",
            "deep_sort/deep/__init__.py\n",
            "deep_sort/deep/datasets.py\n",
            "deep_sort/deep/evaluate.py\n",
            "deep_sort/deep/feature_extractor.py\n",
            "deep_sort/deep/model.py\n",
            "deep_sort/deep/resnet.py\n",
            "deep_sort/deep/test.py\n",
            "deep_sort/deep/train.jpg\n",
            "deep_sort/deep/train.py\n",
            "deep_sort/deep/train_multiGPU.py\n",
            "deep_sort/deep/checkpoint/\n",
            "deep_sort/deep/checkpoint/.gitkeep\n",
            "deep_sort/deep/checkpoint/ckpt.t7\n",
            "deep_sort/deep/multi_train_utils/\n",
            "deep_sort/deep/multi_train_utils/distributed_utils.py\n",
            "deep_sort/deep/multi_train_utils/train_eval_utils.py\n",
            "deep_sort/sort/\n",
            "deep_sort/sort/__init__.py\n",
            "deep_sort/sort/detection.py\n",
            "deep_sort/sort/iou_matching.py\n",
            "deep_sort/sort/kalman_filter.py\n",
            "deep_sort/sort/linear_assignment.py\n",
            "deep_sort/sort/nn_matching.py\n",
            "deep_sort/sort/preprocessing.py\n",
            "deep_sort/sort/track.py\n",
            "deep_sort/sort/tracker.py\n",
            "utils/\n",
            "utils/__init__.py\n",
            "utils/asserts.py\n",
            "utils/draw.py\n",
            "utils/evaluation.py\n",
            "utils/io.py\n",
            "utils/json_logger.py\n",
            "utils/log.py\n",
            "utils/parser.py\n",
            "utils/tools.py\n",
            "\n",
            "sent 46,226,919 bytes  received 1,928 bytes  92,457,694.00 bytes/sec\n",
            "total size is 46,212,388  speedup is 1.00\n",
            "sending incremental file list\n",
            "./\n",
            "best.pt\n",
            "\n",
            "sent 52,041,563 bytes  received 62 bytes  104,083,250.00 bytes/sec\n",
            "total size is 52,028,747  speedup is 1.00\n",
            "/content\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.13 in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 5)) (4.11.0.86)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 7)) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 9)) (2.0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 11)) (1.13)\n",
            "Requirement already satisfied: vizer in /usr/local/lib/python3.11/dist-packages (from -r deep_sort_pytorch/requirements.txt (line 12)) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r deep_sort_pytorch/requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r deep_sort_pytorch/requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r deep_sort_pytorch/requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->-r deep_sort_pytorch/requirements.txt (line 1)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import Libraries"
      ],
      "metadata": {
        "id": "QFIlM4nyZLA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow # cv2.imshow(\"title\", frane) doesn't work in Colab so this is the fix cv2_imshow(frame)\n",
        "from IPython.display import HTML, Video, display\n",
        "from base64 import b64encode\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "zy9ZhKSIPJYa"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Config"
      ],
      "metadata": {
        "id": "krq7bUcrQjle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/dataset\"\n",
        "dataset_data_path = dataset_path + \"/data.yaml\"\n",
        "idx_to_class_path = \"/content/idx_to_class.json\"\n",
        "output_video_path = \"/content/output.mp4\"\n",
        "\n",
        "# Load object detector model\n",
        "model = YOLO(\"/content/yolo/best.pt\")\n",
        "model.info() # Display model information\n",
        "\n",
        "# DeepSORT cfg\n",
        "deep_sort_cfg = {\n",
        "    \"USE_FASTREID\" : False,\n",
        "    'DEEPSORT': {\n",
        "        'REID_CKPT': 'deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7',\n",
        "        'MAX_DIST': 0.2, # Maximum cosine distance\n",
        "        'MIN_CONFIDENCE': 0.5, # Minimum detector confidence\n",
        "        'NMS_MAX_OVERLAP': 0.5, # Maximum IoU for suppressing overlapping boxes.\n",
        "        'MAX_IOU_DISTANCE': 0.5, # 0.7 Max IoU distance for motion-only matching in the cascade.\n",
        "        'MAX_AGE': 70, # Number of consecutive frames a track is kept “alive” without matching.\n",
        "        'N_INIT': 3, # Number of frames a track must be consistently matched before confirmed.\n",
        "        'NN_BUDGET': 100 # Maximum number of appearance features to store per track.\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLBfAejEQouP",
        "outputId": "57cbbb76-f1aa-429f-8e89-139d5d65d196"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 169 layers, 25,856,899 parameters, 0 gradients, 79.1 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Download Dataset"
      ],
      "metadata": {
        "id": "duz7cGimZzoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Download"
      ],
      "metadata": {
        "id": "xJ5WbmvIu8nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_download_path = \"/content/pedestrain-data.zip\""
      ],
      "metadata": {
        "id": "n7RvLUUxu78D"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Unzip"
      ],
      "metadata": {
        "id": "_V6EqaaHZ-Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q {dataset_download_path} -d {dataset_path}\n",
        "!rm -rf {dataset_download_path}"
      ],
      "metadata": {
        "id": "ESNSeVB9Z8yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Functions"
      ],
      "metadata": {
        "id": "ZXbLlwg490q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Play Video"
      ],
      "metadata": {
        "id": "6EgmrYscUfzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def play_video(video_path):\n",
        "  video_info = video_path.rsplit('.')\n",
        "  compressed_video_path = f\"{video_info[0]}_compressed.mp4\"\n",
        "\n",
        "  if video_info[1] == \"avi\":\n",
        "    os.system(f\"ffmpeg -i {video_path} -c:v libx264 -crf 20 -preset slow -pix_fmt yuv420p {video_info[0]}.mp4\")\n",
        "\n",
        "  # compress video file (cant run in colab without compressing)\n",
        "  os.system(f\"ffmpeg -i {video_path[0]}.mp4 -vcodec libx264 {compressed_video_path}\")\n",
        "\n",
        "  display(Video(compressed_video_path, embed=True, width=640))"
      ],
      "metadata": {
        "id": "huSJ-nSc90bM"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train Model"
      ],
      "metadata": {
        "id": "AMnNtf5Tdncp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(data=dataset_data_path, epochs=50, imgsz=640)"
      ],
      "metadata": {
        "id": "Qj7PhCf3doWL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Test Model"
      ],
      "metadata": {
        "id": "TM_vkkrTfrV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "\n",
        "# Run inference with the YOLO model on the validation dataset\n",
        "results = model.predict(source=\"people.mp4\", save=True, verbose=True) # dataset_path + \"/valid/images\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "InlhUZzFfuoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Display Results"
      ],
      "metadata": {
        "id": "Y-9t-uOIsCv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1.1 Play Results Video"
      ],
      "metadata": {
        "id": "0SUBZRApCAhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirs = []\n",
        "base_dir = \"/content/runs/detect\"\n",
        "# List all directories in the base directory\n",
        "for predictFolder in os.listdir(base_dir):\n",
        "  if os.path.isdir(os.path.join(base_dir, predictFolder)):\n",
        "    if predictFolder.startswith('predict'):\n",
        "      # If the directory has a number then extract it\n",
        "      m = re.search(r\"(\\d+)$\", predictFolder)\n",
        "      num = int(m.group(1)) if m else 0\n",
        "      dirs.append((predictFolder, num))\n",
        "\n",
        "if dirs:\n",
        "  dirs.sort(key=lambda x: x[1], reverse=True) # Sort by number in reverse (largest)\n",
        "  latest_pred_dir = dirs[0][0]\n",
        "  latest_pred_dir_path = os.path.join(base_dir, latest_pred_dir)\n",
        "\n",
        "  for f in os.listdir(latest_pred_dir_path):\n",
        "    if f.endswith('.avi'):\n",
        "      play_video(os.path.join(latest_pred_dir_path, f))\n",
        "      break"
      ],
      "metadata": {
        "id": "NK5EKTXKCASQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1.2 From predict function"
      ],
      "metadata": {
        "id": "eiL1e6VXsOJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process results list\n",
        "for result in results[:10]:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    # print(boxes.data.tolist()) # x1, y1, x2, y2, conf score, class id\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen\n",
        "    # result.save(filename=\"result.jpg\")  # save to disk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DZKG_B_SsLU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1.3 From predict folder"
      ],
      "metadata": {
        "id": "1ar0acg1sVWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob(\"runs/detect/predict/*.jpg\")[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SvPEjbGjsXLK"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Run Model"
      ],
      "metadata": {
        "id": "LquV-0VSom6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1 Initalize DeepSORT"
      ],
      "metadata": {
        "id": "9pAI_3PZtohf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_sort_pytorch.deepsort import DeepSortTracker\n",
        "from deep_sort_pytorch.utils.parser import get_config\n",
        "from deep_sort_pytorch.utils.draw import draw_boxes\n",
        "from deep_sort_pytorch.utils.tools import generate_idx_to_class\n",
        "\n",
        "# Import idx_to_class file\n",
        "if os.path.isfile(idx_to_class_path):\n",
        "  with open(idx_to_class_path, 'r') as f:\n",
        "    idx_to_class = json.load(f)\n",
        "else:\n",
        "  idx_to_class = generate_idx_to_class(dataset_data_path)\n",
        "\n",
        "cfg = get_config() # Create new empty dict\n",
        "cfg.merge_from_dict(deep_sort_cfg) # merge dict\n",
        "\n",
        "# Initialize DeepSORT tracker\n",
        "deep_sort_tracker = DeepSortTracker(cfg, use_cuda=True)"
      ],
      "metadata": {
        "id": "lIR4RhEqtn-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2 Images"
      ],
      "metadata": {
        "id": "MKjqQX3kokv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through images/frames\n",
        "for img_path in glob.glob(dataset_path + \"/valid/images/*.jpg\"):\n",
        "\n",
        "    frame = cv2.imread(img_path)\n",
        "    if frame is None:\n",
        "        continue\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model.predict(source=frame, verbose=True)\n",
        "\n",
        "    # Prepare detections for DeepSORT\n",
        "    bbox_xywh = results[0].boxes.xywh.cpu().numpy()\n",
        "    conf = results[0].boxes.conf.cpu().numpy()\n",
        "    cls_ids = results[0].boxes.cls.cpu().numpy()\n",
        "\n",
        "    # Update tracker\n",
        "    outputs, _ = deep_sort_tracker.update(bbox_xywh, conf, cls_ids, frame) #outputs bbox, track id, class\n",
        "\n",
        "    # Draw results\n",
        "    if len(outputs) > 0:\n",
        "      bbox_xyxy = outputs[:, :4] # Bounding Boxes\n",
        "      identities = outputs[:, -1] # Unique Track IDs\n",
        "      cls = outputs[:, -2] # Classes\n",
        "\n",
        "      # Get class names\n",
        "      names = [idx_to_class[str(label)] for label in cls]\n",
        "      # Draw bounding boxes\n",
        "      ori_im = draw_boxes(frame, bbox_xyxy, names, identities)\n",
        "      # Display the frame\n",
        "      cv2_imshow(ori_im)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "3AkMYCfdopDf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.3 Video"
      ],
      "metadata": {
        "id": "_cYngrkgooxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3.1 Run"
      ],
      "metadata": {
        "id": "ZAbiSWqMCU3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_video = True\n",
        "play_frames = False\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/people.mp4\") # Load video\n",
        "\n",
        "ret, frame = cap.read() # Read first frame\n",
        "\n",
        "# Retrieve frame dimensions and frames per second (fps)\n",
        "if save_video:\n",
        "  frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter\n",
        "if save_video:\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 files\n",
        "  out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while ret:\n",
        "  # Perform object detection\n",
        "  results = model.predict(source=frame, verbose=True)\n",
        "\n",
        "  # Prepare detections for DeepSORT\n",
        "  bbox_xywh = results[0].boxes.xywh.cpu().numpy()\n",
        "  conf = results[0].boxes.conf.cpu().numpy()\n",
        "  cls_ids = results[0].boxes.cls.cpu().numpy()\n",
        "\n",
        "  # Update tracker\n",
        "  outputs, _ = deep_sort_tracker.update(bbox_xywh, conf, cls_ids, frame) #outputs bbox, track id, class\n",
        "\n",
        "  # Draw results\n",
        "  if len(outputs) > 0:\n",
        "    bbox_xyxy = outputs[:, :4] # Bounding Boxes\n",
        "    identities = outputs[:, -1] # Unique Track IDs\n",
        "    cls = outputs[:, -2] # Classes\n",
        "\n",
        "    # Get class names\n",
        "    names = [idx_to_class[str(label)] for label in cls]\n",
        "    # Draw bounding boxes\n",
        "    ori_im = draw_boxes(frame, bbox_xyxy, names, identities)\n",
        "\n",
        "  if save_video: out.write(ori_im) # Write current frame to output\n",
        "  if play_frames: cv2_imshow(ori_im) # output current frame\n",
        "\n",
        "  ret, frame = cap.read() # Read next frame\n",
        "\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "if save_video: out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "7HtIy-mEorAq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3.2 Play Video"
      ],
      "metadata": {
        "id": "T8VYE_2qAdrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "play_video(output_video_path)"
      ],
      "metadata": {
        "id": "9OkzcrMFAkHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}